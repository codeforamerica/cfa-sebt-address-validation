{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04fef6b0",
   "metadata": {},
   "source": [
    "## Ensure prerequisites are installed\n",
    "1. Install libpostal\n",
    "    - Instructions\n",
    "        - [Mac/Linux instructions](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-maclinux)\n",
    "        - [Windows instructions](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-windows)\n",
    "    - In building these examples, we used the optional [Senzing data model](https://github.com/Senzing/libpostal-data) for libpostal. Instructions for using this model are [here](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-with-an-alternative-data-model).\n",
    "\n",
    "2. Install Python dependencies\n",
    "    ```bash\n",
    "    pip3 install -r requirements.txt\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f1e5a",
   "metadata": {},
   "source": [
    "## Parsing addresses for pre-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84022959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e10255a",
   "metadata": {},
   "source": [
    "## Building an inverted index for near-dupe matching\n",
    "This sample uses the [open-data list of address points](https://opendata.dc.gov/datasets/DCGIS::address-points/about) from the Washington, D.C. [Master Address Repository (MAR)](https://opendata.dc.gov/pages/addressing-in-dc). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from postal.parser import parse_address\n",
    "from postal.expand import expand_address\n",
    "from postal.near_dupe import near_dupe_hashes\n",
    "\n",
    "flat_map = lambda f, xs: reduce(lambda a, b: a + b, map(f, xs))\n",
    "\n",
    "def get_expansion_hash(expansion):\n",
    "    parsed_address = parse_address(expansion, language='en', country='us')\n",
    "    labels = [p[1] for p in parsed_address]\n",
    "    values = [p[0] for p in parsed_address]\n",
    "    return near_dupe_hashes(labels, values, languages=['en'], address_only_keys=True)\n",
    "\n",
    "def get_hashes(address):\n",
    "    expansions = expand_address(address, languages=['en'])\n",
    "    return flat_map(get_expansion_hash, expansions)\n",
    "\n",
    "def build_inverted_index() -> defaultdict:\n",
    "    mar_address_points = pd.read_csv('./data/mar_address_points.csv', header=0, low_memory=False, dtype={\n",
    "        'ZIPCODE': 'string'\n",
    "    })\n",
    "    mar_address_points = mar_address_points[mar_address_points['ADDRESS_TYPE'] == 'ADDRESS']\n",
    "\n",
    "    index = defaultdict(set)\n",
    "\n",
    "    for row in mar_address_points.itertuples():\n",
    "        formatted=f\"{row.ADDRESS}, {row.CITY}, {row.STATE} {row.ZIPCODE}\"\n",
    "        hashes = list(set(get_hashes(formatted)))\n",
    "        result = (row.MAR_ID, row.ADDRESS, row.ADDRESS_NUMBER, row.ADDRESS_NUMBER_SUFFIX, row.STREET_NAME, row.STREET_TYPE, row.QUADRANT, row.CITY, row.STATE, row.ZIPCODE, row.COUNTRY)\n",
    "\n",
    "        for hash in hashes:\n",
    "            index[hash].add(result)\n",
    "\n",
    "    return index\n",
    "\n",
    "inverted_index = build_inverted_index()\n",
    "\n",
    "# TODO - load some sample addresses and find candidate matches in the inverted index."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
