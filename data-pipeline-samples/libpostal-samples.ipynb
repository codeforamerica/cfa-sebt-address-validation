{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04fef6b0",
   "metadata": {},
   "source": [
    "## Ensure prerequisites are installed\n",
    "1. Install libpostal\n",
    "    - Instructions\n",
    "        - [Mac/Linux instructions](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-maclinux)\n",
    "        - [Windows instructions](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-windows)\n",
    "    - In building these examples, we used the optional [Senzing data model](https://github.com/Senzing/libpostal-data) for libpostal. Instructions for using this model are [here](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-with-an-alternative-data-model).\n",
    "\n",
    "2. Install Python dependencies\n",
    "    ```bash\n",
    "    pip3 install -r requirements.txt\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba48f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "\n",
    "def random_string_edit(text, probability=1.0):\n",
    "    \"\"\"Applies a random edit to the input string with a given probability.\"\"\"\n",
    "    if random.random() < probability:\n",
    "        operation = random.choice(['insert', 'delete', 'substitute', 'transpose'])\n",
    "        index = random.randrange(len(text) + 1)  # +1 for potential insertion at the end\n",
    "\n",
    "        if operation == 'insert':\n",
    "            random_char = random.choice(string.ascii_letters + string.digits + ' ')\n",
    "            return text[:index] + random_char + text[index:]\n",
    "        elif operation == 'delete' and text:  # Ensure text is not empty\n",
    "            return text[:index] + text[index+1:]\n",
    "        elif operation == 'substitute' and text:\n",
    "            random_char = random.choice(string.ascii_letters + string.digits + ' ')\n",
    "            return text[:index] + random_char + text[index+1:]\n",
    "        elif operation == 'transpose' and len(text) >= 2:\n",
    "            idx1 = random.randrange(len(text) - 1)\n",
    "            idx2 = idx1 + 1\n",
    "            list_text = list(text)\n",
    "            list_text[idx1], list_text[idx2] = list_text[idx2], list_text[idx1]\n",
    "            return \"\".join(list_text)\n",
    "    return text  # No edit applied\n",
    "\n",
    "def transform_row(row):\n",
    "    edited_address = random_string_edit(random_string_edit(str(row.ADDRESS)))\n",
    "    return f\"{edited_address}, {row.CITY}, {row.STATE} {row.ZIPCODE}\"\n",
    "\n",
    "mar_address_points = pd.read_csv('./data/mar_address_points.csv', header=0, low_memory=False, dtype={\n",
    "    'ZIPCODE': 'string'\n",
    "})\n",
    "mar_address_points = mar_address_points[mar_address_points['ADDRESS_TYPE'] == 'ADDRESS']\n",
    "\n",
    "sampled = mar_address_points.sample(n=25)\n",
    "transformed = sampled.apply(transform_row, axis=1)\n",
    "\n",
    "df_output = pd.DataFrame({ 'address': transformed, 'original': sampled['ADDRESS'] })\n",
    "df_output.to_csv('./data/address_samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f1e5a",
   "metadata": {},
   "source": [
    "## Parsing addresses for pre-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84022959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218 H STREET NE WASHINGTON DC 20002\n",
      "['1218 h street ne washington district of columbia 20002', '1218 h street ne washington dc 20002', '1218 h street nebraska washington district of columbia 20002', '1218 h street nebraska washington dc 20002', '1218 h street northeast washington district of columbia 20002', '1218 h street northeast washington dc 20002']\n",
      "[('1218', 'postcode'), ('h street ne', 'road'), ('washington', 'city'), ('dc', 'state'), ('20002', 'postcode')]\n",
      "4800 U STREET NW WASHINGTON DC 20007\n",
      "['4800 unit street northwest washington district of columbia 20007', '4800 unit street northwest washington dc 20007', '4800 unit street nw washington district of columbia 20007', '4800 unit street nw washington dc 20007', '4800 u street northwest washington district of columbia 20007', '4800 u street northwest washington dc 20007', '4800 u street nw washington district of columbia 20007', '4800 u street nw washington dc 20007']\n",
      "[('4800', 'postcode'), ('u street nw', 'road'), ('washington', 'city'), ('dc', 'state'), ('20007', 'postcode')]\n",
      "3300 V STREET NE WASHINGTON DC 20018\n",
      "['3300 v street ne washington district of columbia 20018', '3300 5 street ne washington district of columbia 20018', '3300 v street ne washington dc 20018', '3300 5 street ne washington dc 20018', '3300 v street nebraska washington district of columbia 20018', '3300 5 street nebraska washington district of columbia 20018', '3300 v street nebraska washington dc 20018', '3300 5 street nebraska washington dc 20018', '3300 v street northeast washington district of columbia 20018', '3300 5 street northeast washington district of columbia 20018', '3300 v street northeast washington dc 20018', '3300 5 street northeast washington dc 20018']\n",
      "[('3300', 'postcode'), ('v street ne', 'road'), ('washington', 'city'), ('dc', 'state'), ('20018', 'postcode')]\n",
      "No output to write for street_present\n",
      "No output to write for street_missing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from postal.expand import expand_address\n",
    "from postal.parser import parse_address\n",
    "\n",
    "output_directory = './output'\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "def process_row(row):\n",
    "    try:\n",
    "        formatted=f\"{row.ADDRESS} {row.CITY} {row.STATE} {row.ZIPCODE}\"\n",
    "        parsed = parse_address(formatted, language='en', country='us')\n",
    "\n",
    "        keys = [item[1] for item in parsed]\n",
    "        values = [item[0] for item in parsed]\n",
    "\n",
    "        ParseResult = namedtuple('ParseResult', keys)\n",
    "        parse_result = ParseResult(*values)\n",
    "\n",
    "        return None, False\n",
    "\n",
    "        if hasattr(parse_result, 'house_number') and hasattr(parse_result, 'road'):\n",
    "            return parse_result, True\n",
    "        else:\n",
    "            return parse_result, False\n",
    "    except ValueError:\n",
    "        expanded = expand_address(formatted, languages=['en'])\n",
    "\n",
    "        print(formatted)\n",
    "        print(expanded)\n",
    "        print(parsed)\n",
    "\n",
    "        return None, False\n",
    "\n",
    "\n",
    "mar_address_points = pd.read_csv('./data/mar_address_points.csv', header=0, low_memory=False, dtype={\n",
    "    'ZIPCODE': 'string'\n",
    "})\n",
    "\n",
    "street_present = []\n",
    "street_missing = []\n",
    "\n",
    "for row in mar_address_points.itertuples():\n",
    "    result = process_row(row)\n",
    "    processed_data, has_street = result\n",
    "    \n",
    "    if has_street == True:\n",
    "        street_present.append(processed_data._asdict())\n",
    "    elif processed_data != None:\n",
    "        street_missing.append(processed_data._asdict())\n",
    "\n",
    "if street_present:\n",
    "    df_street_present = pd.DataFrame(street_present)\n",
    "    df_street_present.to_csv(os.path.join(output_directory, 'street_present.csv'))\n",
    "else:\n",
    "    print('No output to write for street_present')\n",
    "\n",
    "if street_missing:\n",
    "    df_street_missing = pd.DataFrame(street_missing)\n",
    "    df_street_missing.to_csv(os.path.join(output_directory, 'street_missing.csv'))\n",
    "else:\n",
    "    print('No output to write for street_missing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10255a",
   "metadata": {},
   "source": [
    "## Building an inverted index for near-dupe matching\n",
    "This sample uses the [open-data list of address points](https://opendata.dc.gov/datasets/DCGIS::address-points/about) from the Washington, D.C. [Master Address Repository (MAR)](https://opendata.dc.gov/pages/addressing-in-dc). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from postal.parser import parse_address\n",
    "from postal.expand import expand_address\n",
    "from postal.near_dupe import near_dupe_hashes\n",
    "\n",
    "flat_map = lambda f, xs: reduce(lambda a, b: a + b, map(f, xs))\n",
    "\n",
    "def get_expansion_hash(expansion):\n",
    "    parsed_address = parse_address(expansion, language='en', country='us')\n",
    "    labels = [p[1] for p in parsed_address]\n",
    "    values = [p[0] for p in parsed_address]\n",
    "    return near_dupe_hashes(labels, values, languages=['en'], address_only_keys=True)\n",
    "\n",
    "def get_hashes(address):\n",
    "    expansions = expand_address(address, languages=['en'])\n",
    "    return flat_map(get_expansion_hash, expansions)\n",
    "\n",
    "def build_inverted_index() -> defaultdict:\n",
    "    mar_address_points = pd.read_csv('./data/mar_address_points.csv', header=0, low_memory=False, dtype={\n",
    "        'ZIPCODE': 'string'\n",
    "    })\n",
    "    mar_address_points = mar_address_points[mar_address_points['ADDRESS_TYPE'] == 'ADDRESS']\n",
    "\n",
    "    index = defaultdict(set)\n",
    "\n",
    "    for row in mar_address_points.itertuples():\n",
    "        formatted=f\"{row.ADDRESS}, {row.CITY}, {row.STATE} {row.ZIPCODE}\"\n",
    "        hashes = list(set(get_hashes(formatted)))\n",
    "        result = (row.MAR_ID, row.ADDRESS, row.ADDRESS_NUMBER, row.ADDRESS_NUMBER_SUFFIX, row.STREET_NAME, row.STREET_TYPE, row.QUADRANT, row.CITY, row.STATE, row.ZIPCODE, row.COUNTRY)\n",
    "\n",
    "        for hash in hashes:\n",
    "            index[hash].add(result)\n",
    "\n",
    "    return index\n",
    "\n",
    "inverted_index = build_inverted_index()\n",
    "\n",
    "# TODO - load some sample addresses and find candidate matches in the inverted index."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
