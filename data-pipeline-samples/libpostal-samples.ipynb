{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04fef6b0",
   "metadata": {},
   "source": [
    "## Ensure prerequisites are installed\n",
    "1. Install libpostal\n",
    "    - Instructions\n",
    "        - [Mac/Linux instructions](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-maclinux)\n",
    "        - [Windows instructions](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-windows)\n",
    "    - In building these examples, we used the optional [Senzing data model](https://github.com/Senzing/libpostal-data) for libpostal. Instructions for using this model are [here](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-with-an-alternative-data-model).\n",
    "\n",
    "2. Install Python dependencies\n",
    "    ```bash\n",
    "    pip3 install -r requirements.txt\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d5b3c",
   "metadata": {},
   "source": [
    "## Create random sampling of known addresses with various string edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "\n",
    "def random_string_edit(text, probability=1.0):\n",
    "    \"\"\"Applies a random edit to the input string with a given probability.\"\"\"\n",
    "    if random.random() < probability:\n",
    "        operation = random.choice(['insert', 'delete', 'substitute', 'transpose'])\n",
    "        index = random.randrange(len(text) + 1)  # +1 for potential insertion at the end\n",
    "\n",
    "        if operation == 'insert':\n",
    "            random_char = random.choice(string.ascii_uppercase + string.digits + ' ')\n",
    "            return text[:index] + random_char + text[index:]\n",
    "        elif operation == 'delete' and text:  # Ensure text is not empty\n",
    "            return text[:index] + text[index+1:]\n",
    "        elif operation == 'substitute' and text:\n",
    "            random_char = random.choice(string.ascii_uppercase + string.digits + ' ')\n",
    "            return text[:index] + random_char + text[index+1:]\n",
    "        elif operation == 'transpose' and len(text) >= 2:\n",
    "            idx1 = random.randrange(len(text) - 1)\n",
    "            idx2 = idx1 + 1\n",
    "            list_text = list(text)\n",
    "            list_text[idx1], list_text[idx2] = list_text[idx2], list_text[idx1]\n",
    "            return \"\".join(list_text)\n",
    "    return text  # No edit applied\n",
    "\n",
    "def transform_row(row):\n",
    "    edited_address = random_string_edit(random_string_edit(str(row.ADDRESS)))\n",
    "    return f\"{edited_address}, {row.CITY}, {row.STATE} {row.ZIPCODE}\"\n",
    "\n",
    "mar_address_points = pd.read_csv('./data/mar_address_points.csv', header=0, low_memory=False, dtype={\n",
    "    'ZIPCODE': 'string'\n",
    "})\n",
    "mar_address_points = mar_address_points[mar_address_points['ADDRESS_TYPE'] == 'ADDRESS']\n",
    "\n",
    "sampled = mar_address_points.sample(n=25)\n",
    "transformed = sampled.apply(transform_row, axis=1)\n",
    "\n",
    "df_output = pd.DataFrame({ 'address': transformed, 'original': sampled['ADDRESS'] })\n",
    "df_output.to_csv('./data/address_samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f1e5a",
   "metadata": {},
   "source": [
    "## Parsing addresses for pre-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84022959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from postal.expand import expand_address\n",
    "from postal.parser import parse_address\n",
    "\n",
    "output_directory = './output'\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "def process_row(row):\n",
    "    try:\n",
    "        formatted=f\"{row.ADDRESS} {row.CITY} {row.STATE} {row.ZIPCODE}\"\n",
    "        parsed = parse_address(formatted, language='en', country='us')\n",
    "\n",
    "        keys = [item[1] for item in parsed]\n",
    "        values = [item[0] for item in parsed]\n",
    "\n",
    "        ParseResult = namedtuple('ParseResult', keys)\n",
    "        parse_result = ParseResult(*values)\n",
    "\n",
    "        return None, False\n",
    "\n",
    "        if hasattr(parse_result, 'house_number') and hasattr(parse_result, 'road'):\n",
    "            return parse_result, True\n",
    "        else:\n",
    "            return parse_result, False\n",
    "    except ValueError:\n",
    "        expanded = expand_address(formatted, languages=['en'])\n",
    "\n",
    "        # print(formatted)\n",
    "        # print(expanded)\n",
    "        # print(parsed)\n",
    "\n",
    "        return None, False\n",
    "\n",
    "\n",
    "mar_address_points = pd.read_csv('./data/mar_address_points.csv', header=0, low_memory=False, dtype={\n",
    "    'ZIPCODE': 'string'\n",
    "})\n",
    "\n",
    "street_present = []\n",
    "street_missing = []\n",
    "\n",
    "for row in mar_address_points.itertuples():\n",
    "    result = process_row(row)\n",
    "    processed_data, has_street = result\n",
    "    \n",
    "    if has_street == True:\n",
    "        street_present.append(processed_data._asdict())\n",
    "    elif processed_data != None:\n",
    "        street_missing.append(processed_data._asdict())\n",
    "\n",
    "if street_present:\n",
    "    df_street_present = pd.DataFrame(street_present)\n",
    "    df_street_present.to_csv(os.path.join(output_directory, 'street_present.csv'))\n",
    "else:\n",
    "    print('No output to write for street_present')\n",
    "\n",
    "if street_missing:\n",
    "    df_street_missing = pd.DataFrame(street_missing)\n",
    "    df_street_missing.to_csv(os.path.join(output_directory, 'street_missing.csv'))\n",
    "else:\n",
    "    print('No output to write for street_missing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10255a",
   "metadata": {},
   "source": [
    "## Building an inverted index for near-dupe matching\n",
    "This sample uses the [open-data list of address points](https://opendata.dc.gov/datasets/DCGIS::address-points/about) from the Washington, D.C. [Master Address Repository (MAR)](https://opendata.dc.gov/pages/addressing-in-dc). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079b7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MAR index from file...\n",
      "Searching for matches for: 112T UPSHUR STREE NE, WASHINGTON, DC 20017\n",
      "[('112t', 'house_number'), ('upshur stree ne', 'road'), ('washington', 'city'), ('dc', 'state'), ('20017', 'postcode')]\n",
      "House number: 112t\n",
      "Hashes: ['sct|upshur street ne|washington', 'sct|upshur street nebraska|washington', 'sct|upshur street northeast|washington', 'sct|upshur|washington', 'spc|upshur street ne|20017', 'spc|upshur street nebraska|20017', 'spc|upshur street northeast|20017', 'spc|upshur|20017', 'sct|upshur street ne|washington', 'sct|upshur street nebraska|washington', 'sct|upshur street northeast|washington', 'sct|upshur|washington', 'spc|upshur street ne|20017', 'spc|upshur street nebraska|20017', 'spc|upshur street northeast|20017', 'spc|upshur|20017', 'sct|upshur street|washington', 'sct|upshur street|nebraska', 'sct|upshur|washington', 'sct|upshur|nebraska', 'spc|upshur street|20017', 'spc|upshur|20017', 'sct|upshur street|washington', 'sct|upshur street|nebraska', 'sct|upshur|washington', 'sct|upshur|nebraska', 'spc|upshur street|20017', 'spc|upshur|20017', 'sct|upshur street northeast|washington', 'sct|upshur|washington', 'spc|upshur street northeast|20017', 'spc|upshur|20017', 'sct|upshur street northeast|washington', 'sct|upshur|washington', 'spc|upshur street northeast|20017', 'spc|upshur|20017', 'sct|t upshur street ne|washington', 'sct|t upshur street nebraska|washington', 'sct|t upshur street northeast|washington', 'sct|tupshur|washington', 'spc|t upshur street ne|20017', 'spc|t upshur street nebraska|20017', 'spc|t upshur street northeast|20017', 'spc|tupshur|20017', 'sct|t upshur street ne|washington', 'sct|t upshur street nebraska|washington', 'sct|t upshur street northeast|washington', 'sct|tupshur|washington', 'spc|t upshur street ne|20017', 'spc|t upshur street nebraska|20017', 'spc|t upshur street northeast|20017', 'spc|tupshur|20017', 'sct|t upshur street|washington', 'sct|t upshur street|nebraska', 'sct|tupshur|washington', 'sct|tupshur|nebraska', 'spc|t upshur street|20017', 'spc|tupshur|20017', 'sct|t upshur street|washington', 'sct|t upshur street|nebraska', 'sct|tupshur|washington', 'sct|tupshur|nebraska', 'spc|t upshur street|20017', 'spc|tupshur|20017', 'sct|t upshur street northeast|washington', 'sct|tupshur|washington', 'spc|t upshur street northeast|20017', 'spc|tupshur|20017', 'sct|t upshur street northeast|washington', 'sct|tupshur|washington', 'spc|t upshur street northeast|20017', 'spc|tupshur|20017']\n",
      "Possible MAR IDs {225297, 75810, 75859, 55384, 75898, 303231, 303232, 55455, 75939, 258227, 258231, 258232, 258233, 258234, 258235, 258236, 55497, 248027, 248028, 248058, 248059, 248060, 248061, 248062, 248063, 248064, 248065, 67858, 248082, 248084, 248085, 248083, 258333, 311583, 55586, 258338, 258340, 258339, 258342, 258347, 258348, 258349, 258350, 258352, 258353, 258358, 258359, 258360, 258361, 258362, 258363, 258364, 258373, 258387, 258388, 258389, 258391, 258392, 258397, 258400, 258405, 55657, 258411, 258412, 258413, 258414, 258418, 258419, 258420, 76165, 55694, 244114, 244115, 244116, 244117, 244118, 244119, 244120, 244121, 244122, 246174, 258471, 258472, 76201, 258473, 244140, 258477, 53678, 223664, 51633, 223666, 258483, 258484, 258485, 258486, 258487, 258488, 258489, 258490, 258493, 258494, 258496, 258498, 258504, 258505, 258506, 258510, 303569, 244179, 244180, 244181, 244182, 244183, 244184, 244185, 244186, 244187, 244188, 258526, 258527, 258528, 258529, 51687, 53783, 76311, 252455, 252456, 252462, 252463, 252464, 252465, 252466, 252467, 252468, 252471, 252472, 252473, 252479, 76352, 252485, 252486, 252487, 252488, 252489, 252490, 252491, 252492, 252493, 53838, 252494, 252496, 244305, 244306, 252499, 244308, 244309, 244310, 252498, 252500, 244307, 76393, 72304, 244337, 244338, 244339, 244340, 55925, 244341, 244343, 244344, 244345, 244342, 244361, 244362, 244363, 244364, 244365, 55951, 76432, 244381, 244382, 244383, 244386, 244387, 244388, 244389, 244390, 82604, 55985, 285369, 82631, 285389, 285392, 285393, 53974, 82659, 56056, 54012, 82689, 285447, 285448, 82708, 297752, 310057, 82745, 56168, 54125, 54219, 259092, 259093, 259094, 277526, 259095, 259097, 259098, 259096, 259100, 259101, 259102, 259103, 259104, 259105, 259106, 259107, 259108, 259099, 54323, 259183, 259195, 259196, 259197, 259198, 259199, 259200, 259201, 259202, 259203, 259204, 259205, 259206, 259207, 259208, 259224, 259225, 259226, 259227, 259228, 54437, 259238, 259250, 259251, 259253, 54522, 259357, 255295, 255296, 255297, 255298, 255299, 255300, 255301, 255302, 50569, 284071, 75193, 75220, 284155, 259629, 259638, 259645, 259647, 259648, 50774, 75363, 75391, 54935, 71323, 54957, 75439, 73392, 247496, 247497, 247498, 247499, 71377, 52953, 247518, 75487, 247519, 247521, 247522, 247520, 247524, 247523, 247526, 247527, 247525, 247539, 73463, 75512, 73466, 55059, 53012, 75544, 247597, 247598, 247599, 247600, 247601, 53055, 75588, 73546, 55118, 75635, 53132, 249745, 249746, 249747, 249748, 249749, 249750, 249751, 249752, 249753, 249754, 75682, 307112, 249770, 249771, 249772, 249773, 249774, 249775, 53168, 249777, 249778, 249779, 249780, 249781, 249776, 75719, 53196}\n",
      "Possible addresses: ['MAR_ID', 'ADDRESS', 'ADDRESS_NUMBER']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from fuzzywuzzy import fuzz\n",
    "from postal.parser import parse_address\n",
    "from postal.expand import expand_address\n",
    "from postal.near_dupe import near_dupe_hashes\n",
    "\n",
    "mar_address_points = pd.read_csv('./data/mar_address_points.csv', header=0, low_memory=False, dtype={\n",
    "    'ADDRESS_NUMBER': 'string',\n",
    "    'ZIPCODE': 'string'\n",
    "})\n",
    "mar_address_points = mar_address_points[mar_address_points['ADDRESS_TYPE'] == 'ADDRESS']\n",
    "\n",
    "flat_map = lambda f, xs, **kwargs: reduce(lambda a, b: a + b, map(lambda x: f(x, **kwargs), xs))\n",
    "\n",
    "def get_expansion_hash(expansion, exclude_house_number=False):\n",
    "    parsed_address = parse_address(expansion, language='en', country='us')\n",
    "    labels=[]\n",
    "    values=[]\n",
    "    for value, label in parsed_address:\n",
    "        if exclude_house_number == True and label == 'house_number':\n",
    "            continue\n",
    "        labels.append(label)\n",
    "        values.append(value)\n",
    "    return near_dupe_hashes(labels, values, languages=['en'], address_only_keys=True, )\n",
    "\n",
    "def get_hashes(address, exclude_house_number=False):\n",
    "    expansions = expand_address(address, languages=['en'])\n",
    "    return flat_map(get_expansion_hash, expansions, exclude_house_number=exclude_house_number)\n",
    "\n",
    "def build_inverted_index() -> defaultdict:\n",
    "    index = defaultdict(set)\n",
    "\n",
    "    for row in mar_address_points.itertuples():\n",
    "        formatted=f\"{row.ADDRESS}, {row.CITY}, {row.STATE} {row.ZIPCODE}\"\n",
    "        full_hashes = set(get_hashes(formatted))\n",
    "        no_house_number_hashes = set(get_hashes(formatted, exclude_house_number=True))\n",
    "        hashes = list(full_hashes | no_house_number_hashes)\n",
    "        result = (row.MAR_ID, row.ADDRESS, str(row.ADDRESS_NUMBER), row.ADDRESS_NUMBER_SUFFIX, row.STREET_NAME, row.STREET_TYPE, row.QUADRANT, row.CITY, row.STATE, row.ZIPCODE, row.COUNTRY)\n",
    "\n",
    "        for hash in hashes:\n",
    "            index[hash].add(result)\n",
    "\n",
    "    return index\n",
    "\n",
    "def load_or_build_inverted_index() -> defaultdict:\n",
    "    try:\n",
    "        with open('./data/address_index.pkl', 'rb') as read:\n",
    "            print('Loading MAR index from file...')\n",
    "            return pickle.load(read)\n",
    "    except Exception:\n",
    "        print('Building MAR index from scratch...')\n",
    "        index = build_inverted_index()\n",
    "        with open('./data/address_index.pkl', 'wb') as write:\n",
    "            pickle.dump(index, write)\n",
    "        return index\n",
    "\n",
    "df_samples = pd.read_csv(\"./data/address_samples.csv\")\n",
    "\n",
    "inverted_index = load_or_build_inverted_index()\n",
    "\n",
    "def find_candidate_matches(address: str):\n",
    "    print(f\"Searching for matches for: {address}\")\n",
    "    parsed = parse_address(address, language='en', country='us')\n",
    "    print(parsed)\n",
    "\n",
    "    house_numbers = [n[0] for n in parsed if n[1] == 'house_number']\n",
    "    house_number = house_numbers[0] if str(house_numbers) else None\n",
    "    print(f\"House number: {house_number}\")\n",
    "\n",
    "    candidate_matches = []\n",
    "\n",
    "    hashes = get_hashes(address, exclude_house_number=True)\n",
    "    print(f\"Hashes: {hashes}\")\n",
    "\n",
    "    for hash in hashes:\n",
    "        hash_matches = inverted_index[hash]\n",
    "        for match in hash_matches:\n",
    "            candidate_matches.append(match)\n",
    "\n",
    "    possible_mar_ids = set(map(lambda x: x[0], candidate_matches))\n",
    "    print(f\"Possible MAR IDs\", possible_mar_ids)\n",
    "    possible_addresses = mar_address_points[mar_address_points['MAR_ID'].isin(possible_mar_ids)]\n",
    "    possible_addresses = possible_addresses[['MAR_ID', 'ADDRESS', 'ADDRESS_NUMBER']]\n",
    "\n",
    "    possible_addresses = possible_addresses.loc[possible_addresses['ADDRESS_NUMBER'].apply(lambda x: fuzz.ratio(x[2], house_number) > 0.95)]\n",
    "    # possible_addresses = sorted(possible_addresses, key=lambda x: )\n",
    "    possible_addresses.sort_values(by='ADDRESS_NUMBER', key=lambda x: fuzz.ratio(x, house_number))\n",
    "    print(f\"Possible addresses: {possible_addresses}\")\n",
    "\n",
    "    # filtered_matches = list(filter(lambda x: str(x[2]).startswith(house_number) or house_number.startswith(str(x[2])), candidate_matches))\n",
    "\n",
    "    # print(f\"All candidate matches: {filtered_matches}\")\n",
    "    # print(f\"Set of candidate matches: {set(filtered_matches)}\")\n",
    "    # return set(filtered_matches)\n",
    "    return None\n",
    "\n",
    "for row in df_samples.head(1).itertuples():\n",
    "    address = row.address\n",
    "    original = row.original    \n",
    "    \n",
    "\n",
    "    candidate_matches = find_candidate_matches(address)\n",
    "    print(candidate_matches)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
