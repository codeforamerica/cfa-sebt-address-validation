{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04fef6b0",
   "metadata": {},
   "source": [
    "### Ensure prerequisites are installed\n",
    "1. Install libpostal\n",
    "    - Instructions\n",
    "        - [Mac/Linux instructions](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-maclinux)\n",
    "        - [Windows instructions](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-windows)\n",
    "    - In building these examples, we used the optional [Senzing data model](https://github.com/Senzing/libpostal-data) for libpostal. Instructions for using this model are [here](https://github.com/openvenues/libpostal?tab=readme-ov-file#installation-with-an-alternative-data-model).\n",
    "\n",
    "2. Install Python dependencies\n",
    "    ```bash\n",
    "    pip3 install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "> **Note**: These samples use the [open-data list of address points](https://opendata.dc.gov/datasets/DCGIS::address-points/about) from the Washington, D.C. [Master Address Repository (MAR)](https://opendata.dc.gov/pages/addressing-in-dc). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f1e5a",
   "metadata": {},
   "source": [
    "### Parsing addresses for pre-filtering\n",
    "This sample demostrates the usage of `libpostal` to parse unstructured address data. The MAR address point CSV is structured (city, state, zip are separate fields), so we format the address into a single string before parsing with `libpostal`, which will parse the address into labelled components.\n",
    "\n",
    "The output will be saved to `./output/parsed.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84022959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from postal.parser import parse_address\n",
    "\n",
    "output_directory = './output'\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "def process_row(row):\n",
    "    try:\n",
    "        formatted=f\"{row.ADDRESS} {row.CITY} {row.STATE} {row.ZIPCODE}\"\n",
    "        parsed = parse_address(formatted, language='en', country='us')\n",
    "\n",
    "        keys = [item[1] for item in parsed]\n",
    "        values = [item[0] for item in parsed]\n",
    "\n",
    "        ParseResult = namedtuple('ParseResult', keys)\n",
    "        parse_result = ParseResult(*values)\n",
    "\n",
    "        if hasattr(parse_result, 'house_number') and hasattr(parse_result, 'road'):\n",
    "            return parse_result, True\n",
    "        else:\n",
    "            return parse_result, False\n",
    "    except ValueError:\n",
    "        return None, False\n",
    "\n",
    "mar_address_points = pd.read_csv('./data/mar_address_points.csv', header=0, low_memory=False, dtype={\n",
    "    'ADDRESS_NUMBER': 'string',\n",
    "    'ADDRESS_NUMBER_SUFFIX': 'string',\n",
    "    'ZIPCODE': 'string'\n",
    "})\n",
    "\n",
    "parsed = []\n",
    "\n",
    "for row in mar_address_points.itertuples():\n",
    "    result = process_row(row)\n",
    "    processed_data, has_street = result\n",
    "    \n",
    "    if has_street == True:\n",
    "        parsed.append(processed_data._asdict())\n",
    "if parsed:\n",
    "    df_parsed = pd.DataFrame(parsed)\n",
    "    df_parsed.to_csv(os.path.join(output_directory, 'parsed.csv'))\n",
    "else:\n",
    "    print('No output to write for df_parsed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf766b9",
   "metadata": {},
   "source": [
    "### Define a mapping of common abbrevations to their USPS standard expansions\n",
    "`USPS_SUFFIX_MAP` defines a dictionary of common road suffix abbreviations and their corresponding standard expansions.\n",
    "The `standardize_street_designators` function tokenizes a string, replaces abbreviation tokens with their expansions, and reassembles the string. This allows normalizing `123 Main St` to `123 Main Street`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3235a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "USPS_SUFFIX_MAP = {\n",
    "    # Alleys\n",
    "    \"aly\": \"ALLEY\", \"allee\": \"ALLEY\",\n",
    "\n",
    "    # Annex\n",
    "    \"anx\": \"ANNEX\",\n",
    "\n",
    "    # Arcades\n",
    "    \"arc\": \"ARCADE\",\n",
    "\n",
    "    # Avenues\n",
    "    \"ave\": \"AVENUE\", \"av\": \"AVENUE\", \"avn\": \"AVENUE\",\n",
    "\n",
    "    # Bays\n",
    "    \"bch\": \"BEACH\",\n",
    "\n",
    "    # Bluffs\n",
    "    \"blf\": \"BLUFF\", \"blfs\": \"BLUFFS\",\n",
    "\n",
    "    # Bottoms\n",
    "    \"btm\": \"BOTTOM\", \"btms\": \"BOTTOMS\",\n",
    "\n",
    "    # Boulevards\n",
    "    \"blvd\": \"BOULEVARD\", \"boul\": \"BOULEVARD\",\n",
    "\n",
    "    # Branches\n",
    "    \"br\": \"BRANCH\",\n",
    "\n",
    "    # Bridges\n",
    "    \"brg\": \"BRIDGE\",\n",
    "\n",
    "    # Brooks\n",
    "    \"brk\": \"BROOK\", \"brks\": \"BROOKS\",\n",
    "\n",
    "    # Burgs\n",
    "    \"bg\": \"BURG\", \"bgs\": \"BURGS\",\n",
    "\n",
    "    # Bypasses\n",
    "    \"byp\": \"BYPASS\", \"bypa\": \"BYPASS\", \"bypas\": \"BYPASS\",\n",
    "\n",
    "    # Camps\n",
    "    \"cp\": \"CAMP\",\n",
    "\n",
    "    # Canyons\n",
    "    \"cyn\": \"CANYON\",\n",
    "\n",
    "    # Capes\n",
    "    \"cpe\": \"CAPE\",\n",
    "\n",
    "    # Causeways\n",
    "    \"cswy\": \"CAUSEWAY\", \"cswy\": \"CAUSEWAY\",\n",
    "\n",
    "    # Centers\n",
    "    \"ctr\": \"CENTER\", \"cent\": \"CENTER\", \"cntr\": \"CENTER\", \"centr\": \"CENTER\",\n",
    "\n",
    "    # Circles\n",
    "    \"cir\": \"CIRCLE\", \"circ\": \"CIRCLE\", \"circl\": \"CIRCLE\",\n",
    "\n",
    "    # Courts\n",
    "    \"ct\": \"COURT\", \"cts\": \"COURTS\",\n",
    "\n",
    "    # Coves\n",
    "    \"cov\": \"COVE\", \"covs\": \"COVES\",\n",
    "\n",
    "    # Creeks\n",
    "    \"crk\": \"CREEK\",\n",
    "\n",
    "    # Crescents\n",
    "    \"cres\": \"CRESCENT\", \"crsnt\": \"CRESCENT\", \"crscnt\": \"CRESCENT\",\n",
    "\n",
    "    # Crests\n",
    "    \"crst\": \"CREST\",\n",
    "\n",
    "    # Crossings\n",
    "    \"xing\": \"CROSSING\", \"xng\": \"CROSSING\",\n",
    "\n",
    "    # Dale\n",
    "    \"dl\": \"DALE\", \"dles\": \"DALES\",\n",
    "\n",
    "    # Dams\n",
    "    \"dm\": \"DAM\",\n",
    "\n",
    "    # Divides\n",
    "    \"dv\": \"DIVIDE\", \"dvd\": \"DIVIDE\",\n",
    "\n",
    "    # Drives\n",
    "    \"dr\": \"DRIVE\", \"driv\": \"DRIVE\", \"drv\": \"DRIVE\",\n",
    "\n",
    "    # Estates\n",
    "    \"est\": \"ESTATE\", \"ests\": \"ESTATES\",\n",
    "\n",
    "    # Expressways\n",
    "    \"expy\": \"EXPRESSWAY\", \"expr\": \"EXPRESSWAY\", \"express\": \"EXPRESSWAY\",\n",
    "\n",
    "    # Extensions\n",
    "    \"ext\": \"EXTENSION\", \"exts\": \"EXTENSIONS\",\n",
    "\n",
    "    # Falls\n",
    "    \"fall\": \"FALL\", \"fls\": \"FALLS\",\n",
    "\n",
    "    # Ferries\n",
    "    \"frry\": \"FERRY\", \"fry\": \"FERRY\",\n",
    "\n",
    "    # Fields\n",
    "    \"fld\": \"FIELD\", \"flds\": \"FIELDS\",\n",
    "\n",
    "    # Flats\n",
    "    \"flat\": \"FLAT\", \"flt\": \"FLAT\", \"flts\": \"FLATS\",\n",
    "\n",
    "    # Fords\n",
    "    \"frd\": \"FORD\", \"frds\": \"FORDS\",\n",
    "\n",
    "    # Forests\n",
    "    \"frst\": \"FOREST\",\n",
    "\n",
    "    # Forges\n",
    "    \"frg\": \"FORGE\", \"frgs\": \"FORGES\",\n",
    "\n",
    "    # Forks\n",
    "    \"frk\": \"FORK\", \"frks\": \"FORKS\",\n",
    "\n",
    "    # Forts\n",
    "    \"ft\": \"FORT\",\n",
    "\n",
    "    # Freeways\n",
    "    \"fwy\": \"FREEWAY\",\n",
    "\n",
    "    # Gardens\n",
    "    \"gdn\": \"GARDEN\", \"gdns\": \"GARDENS\", \"grdn\": \"GARDEN\", \"grdns\": \"GARDENS\",\n",
    "\n",
    "    # Gates\n",
    "    \"gtwy\": \"GATEWAY\", \"gatwy\": \"GATEWAY\", \"gatewy\": \"GATEWAY\",\n",
    "\n",
    "    # Glens\n",
    "    \"gln\": \"GLEN\", \"glns\": \"GLENS\",\n",
    "\n",
    "    # Greens\n",
    "    \"grn\": \"GREEN\", \"grns\": \"GREENS\",\n",
    "\n",
    "    # Groves\n",
    "    \"grv\": \"GROVE\", \"grvs\": \"GROVES\",\n",
    "\n",
    "    # Harbors\n",
    "    \"hbr\": \"HARBOR\", \"hbrs\": \"HARBORS\", \"hrbr\": \"HARBOR\",\n",
    "\n",
    "    # Havens\n",
    "    \"hvns\": \"HAVENS\", \"hvn\": \"HAVEN\",\n",
    "\n",
    "    # Heights\n",
    "    \"hgt\": \"HEIGHTS\", \"hgts\": \"HEIGHTS\", \"ht\": \"HEIGHTS\", \"hts\": \"HEIGHTS\",\n",
    "\n",
    "    # Highways\n",
    "    \"hwy\": \"HIGHWAY\", \"highwy\": \"HIGHWAY\", \"hiwy\": \"HIGHWAY\",\n",
    "\n",
    "    # Hills\n",
    "    \"hl\": \"HILL\", \"hls\": \"HILLS\",\n",
    "\n",
    "    # Hollows\n",
    "    \"holw\": \"HOLLOW\", \"hollw\": \"HOLLOW\", \"holws\": \"HOLLOWS\",\n",
    "\n",
    "    # Inlets\n",
    "    \"inlt\": \"INLET\",\n",
    "\n",
    "    # Islands\n",
    "    \"is\": \"ISLAND\", \"isls\": \"ISLANDS\", \"islnd\": \"ISLAND\",\n",
    "\n",
    "    # Isles\n",
    "    \"isle\": \"ISLE\", \"isles\": \"ISLES\",\n",
    "\n",
    "    # Junctions\n",
    "    \"jct\": \"JUNCTION\", \"jctn\": \"JUNCTION\", \"junctn\": \"JUNCTION\", \"juncton\": \"JUNCTION\", \"jcts\": \"JUNCTIONS\",\n",
    "\n",
    "    # Keys\n",
    "    \"ky\": \"KEY\", \"kys\": \"KEYS\",\n",
    "\n",
    "    # Knolls\n",
    "    \"knl\": \"KNOLL\", \"knls\": \"KNOLLS\",\n",
    "\n",
    "    # Lakes\n",
    "    \"lk\": \"LAKE\", \"lks\": \"LAKES\",\n",
    "\n",
    "    # Lands\n",
    "    \"land\": \"LAND\",\n",
    "\n",
    "    # Landings\n",
    "    \"lndg\": \"LANDING\", \"landg\": \"LANDING\", \"lndng\": \"LANDING\",\n",
    "\n",
    "    # Lanes\n",
    "    \"ln\": \"LANE\",\n",
    "\n",
    "    # Light (singular)\n",
    "    \"lgt\": \"LIGHT\",\n",
    "\n",
    "    # Lights (plural)\n",
    "    \"lgts\": \"LIGHTS\",\n",
    "\n",
    "    # Loaf\n",
    "    \"lf\": \"LOAF\",\n",
    "\n",
    "    # Locks\n",
    "    \"lck\": \"LOCK\", \"lcks\": \"LOCKS\",\n",
    "\n",
    "    # Lodges\n",
    "    \"ldg\": \"LODGE\", \"ldge\": \"LODGE\",\n",
    "\n",
    "    # Loops\n",
    "    \"loop\": \"LOOP\",\n",
    "\n",
    "    # Malls\n",
    "    \"mall\": \"MALL\",\n",
    "\n",
    "    # Manors\n",
    "    \"mnr\": \"MANOR\", \"mnrs\": \"MANORS\",\n",
    "\n",
    "    # Meadows\n",
    "    \"mdw\": \"MEADOW\", \"mdws\": \"MEADOWS\",\n",
    "\n",
    "    # Mews\n",
    "    \"mews\": \"MEWS\",\n",
    "\n",
    "    # Mills\n",
    "    \"ml\": \"MILL\", \"mls\": \"MILLS\",\n",
    "\n",
    "    # Missions\n",
    "    \"msn\": \"MISSION\", \"mssn\": \"MISSION\",\n",
    "\n",
    "    # Mount\n",
    "    \"mt\": \"MOUNT\",\n",
    "\n",
    "    # Mountains\n",
    "    \"mtn\": \"MOUNTAIN\", \"mntn\": \"MOUNTAIN\", \"mountin\": \"MOUNTAIN\", \"mtns\": \"MOUNTAINS\",\n",
    "\n",
    "    # Necks\n",
    "    \"nck\": \"NECK\",\n",
    "\n",
    "    # Orchards\n",
    "    \"orch\": \"ORCHARD\", \"orchrd\": \"ORCHARD\",\n",
    "\n",
    "    # Ovals\n",
    "    \"oval\": \"OVAL\",\n",
    "\n",
    "    # Parks\n",
    "    \"park\": \"PARK\", \"prk\": \"PARK\",\n",
    "\n",
    "    # Parkways\n",
    "    \"pky\": \"PARKWAY\", \"pkway\": \"PARKWAY\", \"pkwy\": \"PARKWAY\", \"pkwys\": \"PARKWAYS\",\n",
    "\n",
    "    # Passes\n",
    "    \"pas\": \"PASS\", \"psg\": \"PASSAGE\",\n",
    "\n",
    "    # Paths\n",
    "    \"path\": \"PATH\", \"paths\": \"PATHS\",\n",
    "\n",
    "    # Pikes\n",
    "    \"pike\": \"PIKE\", \"pikes\": \"PIKES\",\n",
    "\n",
    "    # Pines\n",
    "    \"pine\": \"PINE\", \"pines\": \"PINES\",\n",
    "\n",
    "    # Places\n",
    "    \"pl\": \"PLACE\",\n",
    "\n",
    "    # Plains\n",
    "    \"pln\": \"PLAIN\", \"plns\": \"PLAINS\",\n",
    "\n",
    "    # Plazas\n",
    "    \"plz\": \"PLAZA\", \"plza\": \"PLAZA\",\n",
    "\n",
    "    # Points\n",
    "    \"pt\": \"POINT\", \"pts\": \"POINTS\",\n",
    "\n",
    "    # Port\n",
    "    \"prt\": \"PORT\", \"prts\": \"PORTS\",\n",
    "\n",
    "    # Prairie\n",
    "    \"pr\": \"PRAIRIE\", \"prair\": \"PRAIRIE\", \"prr\": \"PRAIRIE\",\n",
    "\n",
    "    # Ranches\n",
    "    \"rnch\": \"RANCH\", \"ranchs\": \"RANCHES\",\n",
    "\n",
    "    # Rapids\n",
    "    \"rpd\": \"RAPID\", \"rpds\": \"RAPIDS\",\n",
    "\n",
    "    # Rest\n",
    "    \"rst\": \"REST\",\n",
    "\n",
    "    # Ridges\n",
    "    \"rdg\": \"RIDGE\", \"rdgs\": \"RIDGES\",\n",
    "\n",
    "    # River\n",
    "    \"riv\": \"RIVER\", \"rvr\": \"RIVER\", \"rivr\": \"RIVER\",\n",
    "\n",
    "    # Roads\n",
    "    \"rd\": \"ROAD\", \"rds\": \"ROADS\",\n",
    "\n",
    "    # Row\n",
    "    \"row\": \"ROW\",\n",
    "\n",
    "    # Rue\n",
    "    \"rue\": \"RUE\",\n",
    "\n",
    "    # Runs\n",
    "    \"run\": \"RUN\", \"runs\": \"RUNS\",\n",
    "\n",
    "    # Shores\n",
    "    \"shl\": \"SHOAL\", \"shls\": \"SHOALS\", \"shr\": \"SHORE\", \"shrs\": \"SHORES\",\n",
    "\n",
    "    # Skyway\n",
    "    \"skwy\": \"SKYWAY\",\n",
    "\n",
    "    # Springs\n",
    "    \"spg\": \"SPRING\", \"spng\": \"SPRING\", \"sprng\": \"SPRING\", \"spgs\": \"SPRINGS\", \"spngs\": \"SPRINGS\", \"sprngs\": \"SPRINGS\",\n",
    "\n",
    "    # Spurs\n",
    "    \"spur\": \"SPUR\", \"spurs\": \"SPURS\",\n",
    "\n",
    "    # Squares\n",
    "    \"sq\": \"SQUARE\", \"sqr\": \"SQUARE\", \"sqre\": \"SQUARE\", \"sqrs\": \"SQUARES\",\n",
    "\n",
    "    # Streets\n",
    "    \"st\": \"STREET\", \"strt\": \"STREET\",\n",
    "\n",
    "    # Summits\n",
    "    \"smt\": \"SUMMIT\", \"sumit\": \"SUMMIT\", \"sumitt\": \"SUMMIT\",\n",
    "\n",
    "    # Terraces\n",
    "    \"ter\": \"TERRACE\", \"terr\": \"TERRACE\",\n",
    "\n",
    "    # Throughway\n",
    "    \"thwy\": \"THROUGHWAY\",\n",
    "\n",
    "    # Traces\n",
    "    \"trce\": \"TRACE\",\n",
    "\n",
    "    # Tracks\n",
    "    \"trak\": \"TRACK\", \"trk\": \"TRACK\", \"trks\": \"TRACKS\",\n",
    "\n",
    "    # Trails\n",
    "    \"trl\": \"TRAIL\", \"trls\": \"TRAILS\",\n",
    "\n",
    "    # Tunnels\n",
    "    \"tunl\": \"TUNNEL\", \"tunl\": \"TUNNEL\", \"tunnl\": \"TUNNEL\", \"tunnels\": \"TUNNELS\",\n",
    "\n",
    "    # Turns\n",
    "    \"turn\": \"TURN\",\n",
    "\n",
    "    # Underpass\n",
    "    \"upas\": \"UNDERPASS\",\n",
    "\n",
    "    # Union\n",
    "    \"un\": \"UNION\", \"uns\": \"UNIONS\",\n",
    "\n",
    "    # Valleys\n",
    "    \"val\": \"VALLEY\", \"vly\": \"VALLEY\", \"vlly\": \"VALLEY\", \"vlys\": \"VALLEYS\",\n",
    "\n",
    "    # Viaduct\n",
    "    \"via\": \"VIADUCT\", \"viadct\": \"VIADUCT\",\n",
    "\n",
    "    # Views\n",
    "    \"vws\": \"VIEWS\", \"vw\": \"VIEW\",\n",
    "\n",
    "    # Villages\n",
    "    \"vlg\": \"VILLAGE\", \"vllg\": \"VILLAGE\", \"vllge\": \"VILLAGE\", \"vlgs\": \"VILLAGES\",\n",
    "\n",
    "    # Ville\n",
    "    \"vl\": \"VILLE\",\n",
    "\n",
    "    # Vista\n",
    "    \"vis\": \"VISTA\", \"vist\": \"VISTA\", \"vst\": \"VISTA\",\n",
    "\n",
    "    # Walks\n",
    "    \"wk\": \"WALK\", \"wlks\": \"WALKS\",\n",
    "\n",
    "    # Walls\n",
    "    \"wall\": \"WALL\",\n",
    "\n",
    "    # Ways\n",
    "    \"way\": \"WAY\", \"ways\": \"WAYS\",\n",
    "\n",
    "    # Wells\n",
    "    \"wl\": \"WELL\", \"wls\": \"WELLS\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f2a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def standardize_street_designators(address_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Standardizes street designator abbreviations in an unstructured address string\n",
    "    using a provided USPS mapping.\n",
    "\n",
    "    Args:\n",
    "        address_string (str): The input address string.\n",
    "        usps_map (dict): A dictionary where keys are lowercase abbreviations\n",
    "                         and values are uppercase USPS standard expansions.\n",
    "\n",
    "    Returns:\n",
    "        str: The address string with standardized street designators.\n",
    "    \"\"\"\n",
    "    # 1. Normalize the input string for consistent processing\n",
    "    #    - Convert to uppercase for lookup against USPS standard (typically uppercase)\n",
    "    #    - Split by common delimiters to help with tokenization (e.g., commas, periods)\n",
    "    #      We'll rely on re.split to handle multiple delimiters.\n",
    "    normalized_string = address_string.upper()\n",
    "    \n",
    "    # Use re.split to tokenize, keeping delimiters for reconstruction if needed,\n",
    "    # or just split by whitespace and common punctuation, then rejoin.\n",
    "    # For simple replacement, splitting by non-alphanumeric characters or whitespace\n",
    "    # and processing each word is often easiest.\n",
    "    \n",
    "    # Pattern to split by any non-alphanumeric character or whitespace.\n",
    "    # This also keeps the delimiters (punctuation, spaces) as separate tokens\n",
    "    # so we can reassemble correctly.\n",
    "    tokens_with_delimiters = re.findall(r'(\\W+|\\w+)', normalized_string)\n",
    "    \n",
    "    output_tokens = []\n",
    "    \n",
    "    for token in tokens_with_delimiters:\n",
    "        # Check if the token is an alphanumeric word (i.e., not punctuation/whitespace)\n",
    "        if re.fullmatch(r'\\w+', token):\n",
    "            # Convert token to lowercase for map lookup\n",
    "            lower_token = token.lower()\n",
    "            if lower_token in USPS_SUFFIX_MAP:\n",
    "                output_tokens.append(USPS_SUFFIX_MAP[lower_token])\n",
    "            else:\n",
    "                output_tokens.append(token) # Keep original if not found\n",
    "        else:\n",
    "            # If it's a delimiter (space, comma, etc.), keep it as is\n",
    "            output_tokens.append(token)\n",
    "            \n",
    "    # Reconstruct the string\n",
    "    return \"\".join(output_tokens).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10255a",
   "metadata": {},
   "source": [
    "### Using Splink record linkage between known address points and sample addresses\n",
    "[Splink](https://moj-analytical-services.github.io/splink/index.html) is a [probabilistic record linkage](https://en.wikipedia.org/wiki/Record_linkage#Probabilistic_record_linkage) library for Python.\n",
    "\n",
    "Here we're using it to link incoming sample addresses (which we standardize and then parse with libpostal) to the list of known addresses in the area. We are defining rules to block on ZIP code and state, as well as matching exactly on address number, state, and zip code. We fuzz match using the Jaro-Winkler string distance algorithm for the street name and city name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from postal.parser import parse_address\n",
    "from splink import DuckDBAPI, Linker, SettingsCreator, block_on\n",
    "import splink.comparison_library as cl\n",
    "\n",
    "def parse_zip_code(address):\n",
    "    parsed = parse_address(address)\n",
    "    return next((n[0] for n in parsed if n[1] == 'postcode'), None)\n",
    "\n",
    "def parse_address_string(address):\n",
    "    def get_value_by_label(tuples_list, target_label):\n",
    "        return next((value for value, label in tuples_list if label == target_label), None)\n",
    "    standarized = standardize_street_designators(address)\n",
    "    parsed = parse_address(standarized, language=\"en\", country=\"us\")\n",
    "    result = {}\n",
    "    result['address_number'] = get_value_by_label(parsed, 'house_number')\n",
    "    result['street'] = get_value_by_label(parsed, 'road')\n",
    "    result['city'] = get_value_by_label(parsed, 'city')\n",
    "    result['state'] = get_value_by_label(parsed, 'state')\n",
    "    result['zip'] = get_value_by_label(parsed, 'postcode')\n",
    "    return result\n",
    "\n",
    "df_mar = pd.read_csv('./data/mar_address_points.csv', header=0, low_memory=False, dtype={\n",
    "    'ADDRESS_NUMBER': 'string',\n",
    "    'ADDRESS_NUMBER_SUFFIX': 'string',\n",
    "    'ZIPCODE': 'string'\n",
    "})\n",
    "df_mar[\"STREET\"] = df_mar[[\"STREET_NAME\",\"STREET_TYPE\", \"QUADRANT\"]].astype(str).stack().str.lower().unstack().agg(' '.join, axis=1)\n",
    "mar_columns=[\"MAR_ID\", \"ADDRESS_NUMBER\", \"STREET\", \"CITY\", \"STATE\", \"ZIPCODE\"]\n",
    "mar_new_columns=[\"unique_id\",\"address_number\",\"street\", \"city\", \"state\",\"zip\"]\n",
    "mar_col_map=dict(zip(mar_columns, mar_new_columns))\n",
    "df_mar = df_mar[mar_columns].rename(columns=mar_col_map)\n",
    "df_mar[\"street\"] = df_mar[\"street\"].str.lower()\n",
    "df_mar[\"city\"] = df_mar[\"city\"].str.lower()\n",
    "df_mar[\"state\"] = df_mar[\"state\"].str.lower()\n",
    "\n",
    "df_samples = pd.read_csv(\"./data/address_samples.csv\")\n",
    "df_samples = pd.json_normalize(df_samples[\"address\"].apply(parse_address_string))\n",
    "df_samples[\"unique_id\"] = df_samples.reset_index(drop=True).index + 1\n",
    "\n",
    "df_mar_duck = duckdb.sql(\"SELECT * FROM df_mar\")\n",
    "df_samples_duck = duckdb.sql(\"SELECT * FROM df_samples\")\n",
    "\n",
    "con = duckdb.connect(\":default:\")\n",
    "db_api = DuckDBAPI(connection=con)\n",
    "\n",
    "settings = SettingsCreator(\n",
    "    link_type=\"link_only\",\n",
    "    blocking_rules_to_generate_predictions=[\n",
    "        block_on(\"state\"),\n",
    "        block_on(\"zip\"),\n",
    "        block_on(\"substr(zip,1,3)\")\n",
    "    ],\n",
    "    comparisons=[\n",
    "        cl.ExactMatch(\"address_number\"),\n",
    "        cl.JaroWinklerAtThresholds(\"street\"),\n",
    "        cl.JaroWinklerAtThresholds(\"city\"),\n",
    "        cl.ExactMatch(\"state\"),\n",
    "        cl.ExactMatch(\"zip\"),\n",
    "    ],\n",
    "\n",
    "    probability_two_random_records_match=1/1e6,\n",
    "    retain_intermediate_calculation_columns=True,\n",
    "    retain_matching_columns=True,\n",
    ")\n",
    "\n",
    "linker = Linker([df_mar_duck, df_samples_duck], settings, db_api)\n",
    "linker.training.estimate_u_using_random_sampling(max_pairs=1e7)\n",
    "linker.visualisations.match_weights_chart()\n",
    "\n",
    "# Execute the record linkage\n",
    "splink_df_predict = linker.inference.predict()\n",
    "\n",
    "df_predict = splink_df_predict.as_pandas_dataframe()\n",
    "threshold = 0.9\n",
    "df_predict = df_predict[df_predict[\"match_probability\"] > threshold]\n",
    "output_cols = [\"unique_id_l\", \"unique_id_r\", \"match_probability\", \"address_number_l\", \"street_l\", \"address_number_r\", \"street_r\"]\n",
    "df_predict = df_predict[output_cols]\n",
    "\n",
    "# Display the results\n",
    "print(df_predict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
